{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "operator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "from collections import Counter, defaultdict\n",
    "from scipy.special import erfinv\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from typing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SeriesLike = Union[pd.Series, pd.DataFrame]\n",
    "ArrayLike = Union[pd.Series, np.array]\n",
    "T = TypeVar(\"T\")\n",
    "OneorMore = Union[T, Iterable[T]]\n",
    "ColumnName = Union[str, List[str]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of torchtable is the Operator. We compose pipelines from Operators to process columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def _most_frequent(x: np.ndarray):\n",
    "    c = Counter(x)\n",
    "    return c.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Operator:\n",
    "    def __init__(self):\n",
    "        self.before = None\n",
    "        self.built = False\n",
    "\n",
    "    def __gt__(self, op: 'Operator') -> 'Operator':\n",
    "        \"\"\"Syntactic sugar for piping\"\"\"\n",
    "        return self.pipe(op)\n",
    "\n",
    "    def __lt__(self, op: 'Operator') -> 'Operator':\n",
    "        \"\"\"Syntactic sugar for hooking\"\"\"\n",
    "        return self.hook(op)\n",
    "    \n",
    "    def pipe(self, op: 'Operator') -> 'Operator':\n",
    "        \"\"\"Connect an operator after this operator.\n",
    "        Returns the connected operator.\n",
    "        \"\"\"\n",
    "        op.before = self\n",
    "        return op\n",
    "    \n",
    "    def hook(self, op: 'Operator') -> 'Operator':\n",
    "        \"\"\"Connect an operator to the beginning of this pipeline. Returns self.\"\"\"\n",
    "        if self.before is not None:\n",
    "            self.before.hook(op)\n",
    "        else:\n",
    "            self.before = op\n",
    "        return self\n",
    "\n",
    "    def apply(self, x: Any, test=False) -> Any:\n",
    "        \"\"\"Takes output of previous stage in the pipeline and produces output.\n",
    "        Override in subclasses.\"\"\"\n",
    "        return None\n",
    "    \n",
    "    def __call__(self, x, **kwargs):\n",
    "        if self.before is not None:\n",
    "            return self.apply(self.before(x, **kwargs), **kwargs)\n",
    "        else:\n",
    "            return self.apply(x, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaOperator(Operator):\n",
    "    \"\"\"Generic operator\"\"\"\n",
    "    def __init__(self, func: Callable[[T], T]=None):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "    \n",
    "    def apply(self, x: Any, test=False) -> Any:\n",
    "        return self.func(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerOperator(Operator):\n",
    "    \"\"\"Wrapper for any stateful transformer with fit and transform methods\"\"\"\n",
    "    def __init__(self, transformer):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer\n",
    "    \n",
    "    def build(self, x: Any) -> None:\n",
    "        self.transformer.fit(x)\n",
    "    \n",
    "    def apply(self, x: Any, test=False):\n",
    "        if not test: self.build(x)\n",
    "        return self.transformer.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Normalizer:\n",
    "    _methods = set([\"Gaussian\", \"RankGaussian\"])\n",
    "\n",
    "    def __init__(self, method):\n",
    "        self.method = method\n",
    "        if method is not None and method not in self._methods:\n",
    "            raise ValueError(f\"Invalid normalization method {method}\")\n",
    "    \n",
    "    def fit(self, x: pd.Series):\n",
    "        if self.method == \"Gaussian\":\n",
    "            self.mean, self.std = x.mean(), x.std()\n",
    "        elif self.method == \"RankGaussian\":\n",
    "            # TODO: store state\n",
    "            pass\n",
    "        return self\n",
    "\n",
    "    def transform(self, x: pd.Series) -> pd.Series:\n",
    "        if self.method == \"Gaussian\":\n",
    "            return (x - self.mean) / (self.std + 1e-8)\n",
    "        elif self.method == \"RankGaussian\":\n",
    "            # TODO: store state\n",
    "            # prevent divergence to infinity by restricting normalized ranks to range[-0.99, 0.99]\n",
    "            x = (rankdata(x) / len(x) - 0.5) * 0.99 * 2\n",
    "            x = erfinv(x)\n",
    "            return (x - x.mean())\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "class Normalize(TransformerOperator):\n",
    "    def __init__(self, method):\n",
    "        super().__init__(_Normalizer(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _MissingFiller:\n",
    "    _method_mapping = {\n",
    "        \"median\": lambda x: x.median(),\n",
    "        \"mean\": lambda x: x.mean(),\n",
    "        \"mode\": lambda x: _most_frequent(x.dropna()),\n",
    "    }\n",
    "    \n",
    "    def __init__(self, method):\n",
    "        if callable(method):\n",
    "            self.method = method\n",
    "        elif method in self._method_mapping:\n",
    "            self.method = self._method_mapping[method]\n",
    "        elif method is None:\n",
    "            self.method = None\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid method of filling missing data: {method}\")\n",
    "        self.na_mapping = {}\n",
    "\n",
    "    def fit(self, x: pd.Series) -> '_MissingFiller':\n",
    "        self.fill_value = self.method(x)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x: pd.Series, test=False) -> pd.Series:\n",
    "        if self.method is not None:\n",
    "            return x.fillna(self.fill_value)\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "class FillMissing(TransformerOperator):\n",
    "    def __init__(self, method):\n",
    "        super().__init__(_MissingFiller(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, min_freq=0, max_features=None,\n",
    "                 handle_unk=False):\n",
    "        if not handle_unk and (max_features is not None or min_freq > 0):\n",
    "            warnings.warn(\"\"\"Setting max_features or min_freq will potentially cause some categories to become unknown.\n",
    "            Set handle_unk to True to handle categories left out due to max_features or min_freq being set.\n",
    "            \"\"\")\n",
    "        self.min_freq = min_freq\n",
    "        self.max_features = max_features\n",
    "        self.handle_unk = handle_unk\n",
    "            \n",
    "    \n",
    "    def fit(self, x: pd.Series) -> 'Vocab':\n",
    "        counter = Counter()\n",
    "        for v in x: counter[v] += 1\n",
    "        \n",
    "        self.index = defaultdict(int)\n",
    "        # if handle unknown category, reserve 0 for unseen categories\n",
    "        idx = 1 if self.handle_unk else 0\n",
    "        for k, c in counter.most_common(self.max_features):\n",
    "            if c < self.min_freq: break\n",
    "            self.index[k] = idx; idx += 1\n",
    "        return self\n",
    "    \n",
    "    def _get_index(self, x):\n",
    "        if x not in self.index and not self.handle_unk:\n",
    "            raise ValueError(\"Found category not in vocabulary. Try setting handle_unk to True.\")\n",
    "        else:\n",
    "            return self.index[x]\n",
    "    \n",
    "    def transform(self, x: pd.Series, test=False) -> pd.Series:\n",
    "        return x.apply(self._get_index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "    \n",
    "class Categorize(TransformerOperator):\n",
    "    \"\"\"Converts categorical data into integer ids\"\"\"\n",
    "    def __init__(self, min_freq=0, max_features=None,\n",
    "                 handle_unk=False):\n",
    "        super().__init__(Vocab(min_freq=min_freq, max_features=max_features,\n",
    "                               handle_unk=handle_unk))\n",
    "    \n",
    "    @property\n",
    "    def vocab_size(self):\n",
    "        return len(self.transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "       [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.r_[[np.arange(10), np.arange(10)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineeringOperator(Operator):\n",
    "    def __init__(self, funcs: List[Callable]):\n",
    "        super().__init__()\n",
    "        self.funcs = funcs\n",
    "\n",
    "    def apply(self, x: pd.Series, test=False) -> np.array:\n",
    "        return np.r_[[f(x) for f in self.funcs]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Field:\n",
    "    \"\"\"Base class for other fields. Can also be instantiated by passing a pipeline.\"\"\"\n",
    "    def __init__(self, pipeline: Operator, name=None,\n",
    "                 is_target=False, continuous=True):\n",
    "        self.pipeline = pipeline\n",
    "        self.name = name\n",
    "        self.is_target = is_target\n",
    "    \n",
    "    def set_source(self, column: SeriesLike) -> None:   \n",
    "        self.source = column\n",
    "    \n",
    "    def compute(self, test=False) -> ArrayLike:\n",
    "        return self.pipeline(self.source, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityField(Field):\n",
    "    def __init__(self, name=None, is_target=False, continuous=True):\n",
    "        super().__init__(LambdaOperator(lambda x: x), name=name,\n",
    "                         is_target=is_target, continous=continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumericField(Field):\n",
    "    def __init__(self, name=None,\n",
    "                 fill_missing=\"median\", normalization=\"Gaussian\",\n",
    "                 is_target=False):\n",
    "        pipeline = FillMissing(fill_missing) > Normalize(normalization)\n",
    "        super().__init__(pipeline, name, is_target, continuous=True)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"NumericField[{self.name}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoricalField(Field):\n",
    "    def __init__(self, name=None, min_freq=0, max_features=None,\n",
    "                 handle_unk=False, is_target=False):\n",
    "        pipeline = Categorize(min_freq=min_freq, max_features=max_features,\n",
    "                              handle_unk=handle_unk)\n",
    "        super().__init__(pipeline, name, is_target, continuous=False)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"CategoricalField[{self.name}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateField:\n",
    "    def __init__(self, name=None, is_target=False):\n",
    "        pipeline = LambdaOperator(lambda s: s.dt) > FeatureEngineeringOperator([\n",
    "            lambda dt: dt.dayofweek,\n",
    "            lambda dt: dt.is_month_end,\n",
    "            lambda dt: dt.is_month_start,\n",
    "        ])\n",
    "        super().__init__(pipeline, name, is_target, continuous=False)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"DateField[{self.name}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatetimeField(Field):\n",
    "    def __init__(self, name=None, is_target=False):\n",
    "        pipeline = LambdaOperator(lambda s: s.dt) > FeatureEngineeringOperator([\n",
    "            lambda dt: dt.dayofweek,\n",
    "            lambda dt: dt.day,\n",
    "            lambda dt: dt.is_month_end,\n",
    "            lambda dt: dt.is_month_start,\n",
    "            lambda dt: dt.hour,\n",
    "        ])\n",
    "        super().__init__(pipeline, name, is_target, continuous=False)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"DatetimeField[{self.name}]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the meat of the implementaion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, examples: Dict[ColumnName, ArrayLike],\n",
    "                 fields: Dict[ColumnName, Field], test=False):\n",
    "        self.examples = examples\n",
    "        self.fields = fields\n",
    "        self.test = test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples.iloc[idx]\n",
    "            \n",
    "    @classmethod\n",
    "    def from_df(cls, df: pd.DataFrame, fields: Dict[ColumnName, OneorMore[Field]],\n",
    "                test=False) -> 'TabularDataset':\n",
    "        # TODO: implement auto handling of fields\n",
    "        missing_cols = set(df.columns) - set(fields.keys())\n",
    "        if len(missing_cols) > 0:\n",
    "            warnings.warn(f\"The following columns are missing from the fields list: {missing_cols}\")\n",
    "        \n",
    "        additional_fields = {}\n",
    "        for k, fld in fields.items():\n",
    "            if fld is None: continue\n",
    "            if isinstance(fld, Field):\n",
    "                fld.set_source(df[k])\n",
    "                if fld.name is None: fld.name = k\n",
    "            else:\n",
    "                # if multiple fields are specified, hook them all to the same column\n",
    "                for i, f in enumerate(fld):\n",
    "                    f.set_source(df[k])\n",
    "                    if f.name is None: f.name = f\"{k}_{i}\"\n",
    "                    additional_fields[f.name] = f\n",
    "        \n",
    "        fields = {k: v for k, v in fields.items() if isinstance(v, Field)}\n",
    "        fields.update(additional_fields)\n",
    "        examples = {}\n",
    "        for fld in fields.values():\n",
    "            # TODO: Handle multidimensional outputs\n",
    "            examples[fld.name] = fld.compute(test=test)\n",
    "        return cls(examples, fields, test=test)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dfs(cls, train_df: pd.DataFrame, \n",
    "                 val_df: pd.DataFrame=None, test_df: pd.DataFrame=None,\n",
    "                 fields: Dict[ColumnName, OneorMore[Field]]=None) -> Iterable['TabularDataset']:\n",
    "        train = cls.from_df(train_df, fields, test=False)\n",
    "        yield train\n",
    "        if val_df is not None:\n",
    "            yield cls.from_df(val_df, fields, test=True)\n",
    "        if test_df is not None:\n",
    "            non_target_fields = {k: v for k, v in train.fields if not v.is_target}                \n",
    "            yield cls.from_df(test_df, non_target_fields, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_pipe()\n",
    "op1 = LambdaOperator(lambda x: x + 1)\n",
    "op2 = op1 > LambdaOperator(lambda x: x ** 2)\n",
    "assert op2(1) == 4\n",
    "op3 = LambdaOperator(lambda x: x + 3)\n",
    "op2 > op3\n",
    "assert op3(2) == 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_hook()\n",
    "op1 = LambdaOperator(lambda x: x + 3)\n",
    "op2 = LambdaOperator(lambda x: x * 2)\n",
    "op2 < op1\n",
    "assert op2(1) == 8\n",
    "op3 = LambdaOperator(lambda x: x ** 2)\n",
    "op3 < op2\n",
    "assert op3(1) == 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_normalizer_gaussian\n",
    "norm = Normalize(\"Gaussian\")\n",
    "rng = np.random.RandomState(21)\n",
    "a = rng.normal(4, 10, (200, ))\n",
    "a_normed = norm(a)\n",
    "np.testing.assert_almost_equal(a_normed.mean(), 0.)\n",
    "np.testing.assert_almost_equal(a_normed.std(), 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_normalizer_rank_gaussian\n",
    "norm = Normalize(\"RankGaussian\")\n",
    "rng = np.random.RandomState(21)\n",
    "a = rng.normal(4, 10, (200, ))\n",
    "a_normed = norm(a)\n",
    "np.testing.assert_almost_equal(a_normed.mean(), 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_missing_filler\n",
    "rng = np.random.RandomState(21)\n",
    "x = pd.Series(data=rng.normal(0, 1, (100, )))\n",
    "x[x < 0] = np.nan\n",
    "for mthd in [\"median\", \"mean\", \"mode\"]:\n",
    "    filler = FillMissing(mthd)\n",
    "    assert not pd.isnull(filler(x)).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_categorize\n",
    "rng = np.random.RandomState(21)\n",
    "a = pd.Series(data=rng.randint(0, 20, (100, )))\n",
    "cat = Categorize()\n",
    "a_transformed = cat(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_categorize_min_max_freq\n",
    "rng = np.random.RandomState(21)\n",
    "a = pd.Series(data=np.array([1, 2, 1, 4, 1, 2, 3, 3, 5]))\n",
    "cat = Categorize(min_freq=2, max_features=None, handle_unk=True)\n",
    "a_transformed = cat(a)\n",
    "assert (a_transformed[a == 4] == 0).all()\n",
    "assert (a_transformed[a == 5] == 0).all()\n",
    "assert (a_transformed[a == 1] != 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_categorize_unknown\n",
    "rng = np.random.RandomState(21)\n",
    "a = pd.Series(data=np.array([0, 6, 7, 8, 9, 6, 3, 1, 2, 4]))\n",
    "cat = Categorize(min_freq=0, max_features=None, handle_unk=True)\n",
    "cat(pd.Series(data=np.arange(6)))\n",
    "a_transformed = cat(a, test=True)\n",
    "assert (a_transformed[a > 5] == 0).all()\n",
    "assert (a_transformed[a <= 5] > 0).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"sample.csv\", parse_dates=[\"purchase_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authorized_flag</th>\n",
       "      <th>card_id</th>\n",
       "      <th>city_id</th>\n",
       "      <th>category_1</th>\n",
       "      <th>installments</th>\n",
       "      <th>category_3</th>\n",
       "      <th>merchant_category_id</th>\n",
       "      <th>merchant_id</th>\n",
       "      <th>month_lag</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>category_2</th>\n",
       "      <th>state_id</th>\n",
       "      <th>subsector_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>80</td>\n",
       "      <td>M_ID_e020e9b302</td>\n",
       "      <td>-8</td>\n",
       "      <td>-0.703331</td>\n",
       "      <td>2017-06-25 15:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "      <td>C_ID_4e6213e9bc</td>\n",
       "      <td>88</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>367</td>\n",
       "      <td>M_ID_86ec983688</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.733128</td>\n",
       "      <td>2017-07-15 12:10:45</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  authorized_flag          card_id  city_id category_1  installments  \\\n",
       "0               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "1               Y  C_ID_4e6213e9bc       88          N             0   \n",
       "\n",
       "  category_3  merchant_category_id      merchant_id  month_lag  \\\n",
       "0          A                    80  M_ID_e020e9b302         -8   \n",
       "1          A                   367  M_ID_86ec983688         -7   \n",
       "\n",
       "   purchase_amount       purchase_date  category_2  state_id  subsector_id  \n",
       "0        -0.703331 2017-06-25 15:33:07         1.0        16            37  \n",
       "1        -0.733128 2017-07-15 12:10:45         1.0        16            16  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"purchase_date\"].max() - df[\"purchase_date\"].min()).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       175\n",
       "1       195\n",
       "2       220\n",
       "3       243\n",
       "4        67\n",
       "5       418\n",
       "6        78\n",
       "7       321\n",
       "8       151\n",
       "9        74\n",
       "10      128\n",
       "11      403\n",
       "12      158\n",
       "13      194\n",
       "14      296\n",
       "15      163\n",
       "16      402\n",
       "17      187\n",
       "18      372\n",
       "19      222\n",
       "20      241\n",
       "21      181\n",
       "22      194\n",
       "23      125\n",
       "24       18\n",
       "25      421\n",
       "26      118\n",
       "27      173\n",
       "28       68\n",
       "29      216\n",
       "       ... \n",
       "9969    308\n",
       "9970      0\n",
       "9971    312\n",
       "9972     28\n",
       "9973    216\n",
       "9974    101\n",
       "9975    313\n",
       "9976     64\n",
       "9977    197\n",
       "9978     55\n",
       "9979     95\n",
       "9980    258\n",
       "9981    300\n",
       "9982     82\n",
       "9983    205\n",
       "9984    301\n",
       "9985    191\n",
       "9986    170\n",
       "9987    119\n",
       "9988    291\n",
       "9989    287\n",
       "9990    198\n",
       "9991      1\n",
       "9992     27\n",
       "9993    286\n",
       "9994    312\n",
       "9995    100\n",
       "9996    102\n",
       "9997    327\n",
       "9998    202\n",
       "Name: purchase_date, Length: 9999, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df[\"purchase_date\"] - df[\"purchase_date\"].min()).apply(lambda s: s.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_start(x, op):\n",
    "    op.start_date = x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/keitakurita/miniconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Setting max_features or min_freq will potentially cause some categories to become unknown.\n",
      "            Set handle_unk to True to handle categories left out due to max_features or min_freq being set.\n",
      "            \n",
      "  import sys\n",
      "/Users/keitakurita/miniconda3/envs/dl/lib/python3.6/site-packages/ipykernel_launcher.py:21: UserWarning: The following columns are missing from the fields list: {'category_1', 'state_id', 'month_lag', 'card_id', 'purchase_amount', 'merchant_category_id', 'subsector_id', 'category_3', 'city_id', 'merchant_id'}\n"
     ]
    }
   ],
   "source": [
    "train = TabularDataset.from_df(df, fields={\n",
    "    \"installments\": NumericField(normalization=None),\n",
    "    \"category_2\": NumericField(normalization=None),\n",
    "    \"authorized_flag\": CategoricalField(min_freq=3),\n",
    "    \"purchase_date\": [\n",
    "        DatetimeField(),\n",
    "#         Field(LambdaOperator(lambda x,op: (x - op.start_date).apply(lambda d: d.days),\n",
    "#                              build_func=register_start),\n",
    "#               name=\"elapsed_time\", continuous=True)\n",
    "    ]\n",
    "}, test=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = df[\"purchase_date\"].dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       33\n",
       "1       10\n",
       "2        4\n",
       "3        6\n",
       "4       14\n",
       "5       45\n",
       "6       10\n",
       "7        5\n",
       "8        2\n",
       "9       41\n",
       "10      42\n",
       "11       5\n",
       "12       2\n",
       "13      59\n",
       "14      29\n",
       "15      40\n",
       "16      19\n",
       "17       3\n",
       "18      54\n",
       "19      53\n",
       "20      53\n",
       "21      27\n",
       "22       6\n",
       "23      29\n",
       "24      16\n",
       "25      54\n",
       "26      30\n",
       "27      43\n",
       "28      46\n",
       "29      10\n",
       "        ..\n",
       "9969    38\n",
       "9970    46\n",
       "9971    11\n",
       "9972    17\n",
       "9973    47\n",
       "9974    10\n",
       "9975    54\n",
       "9976    10\n",
       "9977    53\n",
       "9978    47\n",
       "9979    34\n",
       "9980     4\n",
       "9981     1\n",
       "9982    52\n",
       "9983    40\n",
       "9984    58\n",
       "9985     4\n",
       "9986    10\n",
       "9987    46\n",
       "9988     0\n",
       "9989    22\n",
       "9990    47\n",
       "9991    57\n",
       "9992     3\n",
       "9993     9\n",
       "9994     0\n",
       "9995    37\n",
       "9996    51\n",
       "9997     0\n",
       "9998     2\n",
       "Name: purchase_date, Length: 9999, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
