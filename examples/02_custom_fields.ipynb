{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will learn more about the internals of torchtable as well as how to construct custom fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the same data that we used in 01_introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"application_train.csv\")\n",
    "test_df = pd.read_csv(\"application_test.csv\")\n",
    "df = df[df.columns[:15]]\n",
    "test_df = df[[x for x in df.columns[:15] if x != \"TARGET\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we wanted to engineer a feature that represented whether a user is a single mother. This is not something that is possible with the regular `NumericField` or `CategoricalField`. Thankfully, torchtable recognizes that feature engineering can be critical in success for tabular datasets, so provides rich support for custom Fields. Let's see how we can construct one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtable.field import Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the number of children, gender, and family status of the user to check if they are a single mother."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_single_mother(row, **kwargs):\n",
    "    return ((row[\"CNT_CHILDREN\"] > 0) & \n",
    "            (row[\"CODE_GENDER\"] == \"M\") & \n",
    "            (row[\"NAME_FAMILY_STATUS\"] != \"Married\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function must take the `train` keyword argument that specifies whether the data being passed should be used to fit/train the function. Since our function is stateless, we can just ignore this argument. \n",
    "\n",
    "To construct a custom field, all we need to do is to pass this feature extraction function to the `Field` constructor along with whether it is a categorical/continuous field. For custom categorical fields, if we want to use automatic model construction we will need to explicitly pass the cardinality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_field = Field(is_single_mother, categorical=True, continuous=False, cardinality=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test if the field works as expected, try calling its `transform` method on some sample input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_field.transform(df[[\"CNT_CHILDREN\", \"CODE_GENDER\", \"NAME_FAMILY_STATUS\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is all fine, but what if we want to do something more complex? For instance, suppose we wanted to allocate a single category to each *combination* of gender and status of having children. We could write a single function to handle this, but torchtable makes such composite pipelines easy to write using `Operator`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will now take a quick detour to explain `Operator`s in torchtable, then use these to create a more advanced feature engineering pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtable.operator import LambdaOperator, Categorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators are - as their names suggest - a single operation on input data. Let's take the following simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op1 = LambdaOperator(lambda x: x + 1)\n",
    "op1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nothing complex going on here. Where `Operator`s really shine is when they are chained to each other. Take the following example where we add 1 to an input, then multiply it by 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op2 = LambdaOperator(lambda x: x * 3)\n",
    "op1 > op2 # we chain operations like this. this means op1's output is fed to op2\n",
    "op2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, chaining op1 and op2 changes op2 into a composite operation. This flexibility makes it easy to write complex pipelines in an intuitive manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get back to the earlier example. We will first want to convert the gender and children status of the user into a single column, then categorize it. We can use the `operator.Categorize` operator to help us here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_child_status = LambdaOperator(lambda x: x.apply(\n",
    "    lambda row: f\"{row['CODE_GENDER']}_{row['CNT_CHILDREN'] > 0}\",\n",
    "    axis=1)\n",
    ")\n",
    "ctgrz = Categorize(handle_unk=False)\n",
    "custom_field2 = Field(\n",
    "    gender_child_status > ctgrz, categorical=True, continuous=False,\n",
    "    cardinality=6, # three gender categories * two child statuses\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_field2.transform(df[[\"CNT_CHILDREN\", \"CODE_GENDER\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building and Training a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the rest is virtually the same as the first tutorial. We do the hard work of thinking of the appropriate pipeline, and torchtable does all the remaining hard work for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtable.field import NumericField, CategoricalField\n",
    "from torchtable.dataset import TabularDataset\n",
    "from torchtable.loader import DefaultLoader\n",
    "from torchtable.model import BatchHandlerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns are missing from the fields list: {'SK_ID_CURR'}\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = TabularDataset.from_dfs(train_df, val_df=val_df, test_df=test_df, fields={\n",
    "    (\"CNT_CHILDREN\", \"CODE_GENDER\", \"NAME_FAMILY_STATUS\"): custom_field, # Our custom field!\n",
    "    (\"CNT_CHILDREN\", \"CODE_GENDER\"): custom_field2,\n",
    "    \"SK_ID_CURR\": None,\n",
    "    \"TARGET\": NumericField(normalization=None, fill_missing=None, is_target=True),\n",
    "    \"NAME_CONTRACT_TYPE\": CategoricalField(),\n",
    "    \"CODE_GENDER\": CategoricalField(),\n",
    "    \"FLAG_OWN_CAR\": CategoricalField(),\n",
    "    \"FLAG_OWN_REALTY\": CategoricalField(),\n",
    "    \"CNT_CHILDREN\": [NumericField(normalization=\"MinMax\"), CategoricalField(handle_unk=True)],\n",
    "    \"AMT_INCOME_TOTAL\": NumericField(normalization=\"RankGaussian\"),\n",
    "    \"AMT_CREDIT\": NumericField(normalization=\"Gaussian\"),\n",
    "    \"AMT_ANNUITY\": NumericField(normalization=\"Gaussian\"),\n",
    "    \"AMT_GOODS_PRICE\": NumericField(normalization=\"Gaussian\"),\n",
    "    \"NAME_TYPE_SUITE\": CategoricalField(),\n",
    "    \"NAME_INCOME_TYPE\": CategoricalField(handle_unk=True),\n",
    "    \"NAME_EDUCATION_TYPE\": CategoricalField(),\n",
    "    \"NAME_FAMILY_STATUS\": CategoricalField(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl = DefaultLoader.from_datasets(train_ds, (32, 32, 128),  val_ds=val_ds, test_ds=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleModel(nn.Module):\n",
    "    def __init__(self, ds):\n",
    "        super().__init__()\n",
    "        self.batch_handler = BatchHandlerModel.from_dataset(ds)\n",
    "        self.l1 = nn.Linear(self.batch_handler.out_dim(), 32)\n",
    "        self.l2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_handler(x)\n",
    "        x = self.l1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SampleModel(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7208/7208 [00:26<00:00, 268.32it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.2771, Validation Loss: 0.2693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7208/7208 [00:26<00:00, 268.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.2750, Validation Loss: 0.2687\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(1, 3):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y[\"TARGET\"].unsqueeze(1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.item() * len(y[\"TARGET\"])\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_ds)\n",
    "    \n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in val_dl:\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y[\"TARGET\"].unsqueeze(1))\n",
    "        val_loss += loss.item() * len(y[\"TARGET\"])\n",
    "\n",
    "    val_loss /= len(val_ds)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
