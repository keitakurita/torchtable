{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, thanks for taking an interest in torchtable! In this notebook, we will be going through a simple example illustrating how to apply torchtable to a dataset on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will download the sample data for this example. If you have not already, please install the kaggle cli via \n",
    "\n",
    "`$ pip install kaggle`\n",
    "\n",
    "In this example, we will be using the data from the [home credit default risk competition](https://www.kaggle.com/c/home-credit-default-risk), a competition for predicting which users will default on a home loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the kaggle cli to obtain the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c home-credit-default-risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip application_train.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip application_test.csv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read the data and take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"application_train.csv\")\n",
    "test_df = pd.read_csv(\"application_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 122), (48744, 121))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "\n",
       "              ...              FLAG_DOCUMENT_18 FLAG_DOCUMENT_19  \\\n",
       "0             ...                             0                0   \n",
       "1             ...                             0                0   \n",
       "\n",
       "  FLAG_DOCUMENT_20 FLAG_DOCUMENT_21 AMT_REQ_CREDIT_BUREAU_HOUR  \\\n",
       "0                0                0                        0.0   \n",
       "1                0                0                        0.0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_DAY  AMT_REQ_CREDIT_BUREAU_WEEK  \\\n",
       "0                       0.0                         0.0   \n",
       "1                       0.0                         0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_MON  AMT_REQ_CREDIT_BUREAU_QRT  \\\n",
       "0                        0.0                        0.0   \n",
       "1                        0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                         1.0  \n",
       "1                         0.0  \n",
       "\n",
       "[2 rows x 122 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of columns...For now, we will subsample the columns to make this example easier to understand. In future examples, we will see how torchtable can automate the process of feature processing for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.columns[:15]]\n",
    "test_df = test_df[[c for c in df.columns[:15] if c != \"TARGET\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the heart of torchtext is the TabularDataset. We'll see how to use this via a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtable import *\n",
    "from torchtable.field import *\n",
    "from torchtable.dataset import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In torchtable, we can easily and declaratively define how we want to process each column/columns in the dataset. Let's see how through an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n",
       "       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n",
       "       'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE',\n",
       "       'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns are missing from the fields list: {'SK_ID_CURR'}\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = TabularDataset.from_dfs(train_df, val_df=val_df, test_df=test_df, fields={\n",
    "    \"SK_ID_CURR\": None,\n",
    "    \"TARGET\": NumericField(normalization=None, fill_missing=None, is_target=True),\n",
    "    \"NAME_CONTRACT_TYPE\": CategoricalField(),\n",
    "    \"CODE_GENDER\": CategoricalField(),\n",
    "    \"FLAG_OWN_CAR\": CategoricalField(),\n",
    "    \"FLAG_OWN_REALTY\": CategoricalField(),\n",
    "    \"CNT_CHILDREN\": [NumericField(normalization=\"MinMax\"), CategoricalField(handle_unk=True)],\n",
    "    \"AMT_INCOME_TOTAL\": NumericField(normalization=\"RankGaussian\"),\n",
    "    \"AMT_CREDIT\": NumericField(normalization=\"Gaussian\"),\n",
    "    \"AMT_ANNUITY\": NumericField(normalization=\"Gaussian\"),\n",
    "    \"AMT_GOODS_PRICE\": NumericField(normalization=\"Gaussian\"),\n",
    "    \"NAME_TYPE_SUITE\": CategoricalField(),\n",
    "    \"NAME_INCOME_TYPE\": CategoricalField(handle_unk=True),\n",
    "    \"NAME_EDUCATION_TYPE\": CategoricalField(),\n",
    "    \"NAME_FAMILY_STATUS\": CategoricalField(),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of information here, so let's pick it apart piece by piece.\n",
    "\n",
    "First off, we're calling the `TabularDataset.from_dfs` method, which allows us to construct one dataset for a train, val, and test dataframe with (virtually) the same processing.\n",
    "\n",
    "The most important part of the above code is the **fields** dictionary. For each column in the input, we are mapping a field or fields. Each field represents a collection of processing steps to apply to each column. We'll discuss this in more depth later and in subsequent example notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we set field to be None, we are ignoring the column. The SK_ID_CURR field is unlikely to help us during training, so we'll be removing it for now. Though the same can be accomplished by not having \"SK_ID_CURR\" be a key in the fields dictionary, it is best practice to map fields to None to make this explicit. This is to distinguish ignored fields from those that you have just forgotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look more deeply into the fields. As you will see, there are two main types of fields: **Numeric** and **Categorical**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET': NumericField[TARGET],\n",
       " 'NAME_CONTRACT_TYPE': CategoricalField[NAME_CONTRACT_TYPE],\n",
       " 'CODE_GENDER': CategoricalField[CODE_GENDER],\n",
       " 'FLAG_OWN_CAR': CategoricalField[FLAG_OWN_CAR],\n",
       " 'FLAG_OWN_REALTY': CategoricalField[FLAG_OWN_REALTY],\n",
       " 'CNT_CHILDREN': [NumericField[CNT_CHILDREN/_0],\n",
       "  CategoricalField[CNT_CHILDREN/_1]],\n",
       " 'AMT_INCOME_TOTAL': NumericField[AMT_INCOME_TOTAL],\n",
       " 'AMT_CREDIT': NumericField[AMT_CREDIT],\n",
       " 'AMT_ANNUITY': NumericField[AMT_ANNUITY],\n",
       " 'AMT_GOODS_PRICE': NumericField[AMT_GOODS_PRICE],\n",
       " 'NAME_TYPE_SUITE': CategoricalField[NAME_TYPE_SUITE],\n",
       " 'NAME_INCOME_TYPE': CategoricalField[NAME_INCOME_TYPE],\n",
       " 'NAME_EDUCATION_TYPE': CategoricalField[NAME_EDUCATION_TYPE],\n",
       " 'NAME_FAMILY_STATUS': CategoricalField[NAME_FAMILY_STATUS]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric fields represent columns that should be treated as continuous numbers. \n",
    "\n",
    "In contrast, Categorical fields represent columns whose values represent some discrete category. \n",
    "\n",
    "Numeric fields are normalized and have their missing values filled, while categorical fields are mapped to discrete integer ids. You can specify the behavior of both fields in detail by setting various parameters (e.g. handle_unk: whether to allow categories that are unseen in the train set). See documentation for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also specify mulitple fields for a single column. In this case, we treat the number of children both as a numerical field and as a categorical field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NumericField[CNT_CHILDREN/_0], CategoricalField[CNT_CHILDREN/_1]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.fields[\"CNT_CHILDREN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a special keyword `is_target` that represent whether a field is a target field (i.e. the label in supervised learning). This does not affect the processing in any way, but is important in handling the train and test datasets. To see why, ley's take a look at the fields in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NAME_CONTRACT_TYPE': CategoricalField[NAME_CONTRACT_TYPE],\n",
       " 'CODE_GENDER': CategoricalField[CODE_GENDER],\n",
       " 'FLAG_OWN_CAR': CategoricalField[FLAG_OWN_CAR],\n",
       " 'FLAG_OWN_REALTY': CategoricalField[FLAG_OWN_REALTY],\n",
       " 'CNT_CHILDREN': [NumericField[CNT_CHILDREN/_0],\n",
       "  CategoricalField[CNT_CHILDREN/_1]],\n",
       " 'AMT_INCOME_TOTAL': NumericField[AMT_INCOME_TOTAL],\n",
       " 'AMT_CREDIT': NumericField[AMT_CREDIT],\n",
       " 'AMT_ANNUITY': NumericField[AMT_ANNUITY],\n",
       " 'AMT_GOODS_PRICE': NumericField[AMT_GOODS_PRICE],\n",
       " 'NAME_TYPE_SUITE': CategoricalField[NAME_TYPE_SUITE],\n",
       " 'NAME_INCOME_TYPE': CategoricalField[NAME_INCOME_TYPE],\n",
       " 'NAME_EDUCATION_TYPE': CategoricalField[NAME_EDUCATION_TYPE],\n",
       " 'NAME_FAMILY_STATUS': CategoricalField[NAME_FAMILY_STATUS]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that the TARGET field is missing. This is because we set `is_target=True` in the field for TARGET. Target fields should not be present in test sets, and we handle this automatically behind the scenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further deepen our understanding, let's take a look at what's inside the dataset. PyTorch datasets can be indexed like a list, so we'll check the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TARGET': 0,\n",
       " 'NAME_CONTRACT_TYPE': 0,\n",
       " 'CODE_GENDER': 0,\n",
       " 'FLAG_OWN_CAR': 0,\n",
       " 'FLAG_OWN_REALTY': 0,\n",
       " 'CNT_CHILDREN': [0.05263157891966759, 2],\n",
       " 'AMT_INCOME_TOTAL': -1.1287163254695256,\n",
       " 'AMT_CREDIT': -1.2731855305872526,\n",
       " 'AMT_ANNUITY': -1.5177575690066853,\n",
       " 'AMT_GOODS_PRICE': -1.2502974913704445,\n",
       " 'NAME_TYPE_SUITE': 0,\n",
       " 'NAME_INCOME_TYPE': 1,\n",
       " 'NAME_EDUCATION_TYPE': 0,\n",
       " 'NAME_FAMILY_STATUS': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For columns with multiple fields, there are multiple outputs as well. As you can see, none of these values are tensors yet. Preprocessing the data is the job of the TabularDataset. Now, let's prepare the data to be fed into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't use the dataset for training yet, since we haven't converted the inputs into minibatches of tensors. Thankfully, this functionality is also provided within torchtable in the form of the `DefaultLoader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtable.loader import DefaultLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DefaultLoaders can also be created with an API similar to that for the TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, val_dl, test_dl = DefaultLoader.from_datasets(train_ds, (32, 32, 128),  val_ds=val_ds, test_ds=test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what a batch looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'NAME_CONTRACT_TYPE': tensor([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "          0, 0, 0, 0, 0, 0, 1, 0]),\n",
       "  'CODE_GENDER': tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "          1, 0, 1, 0, 0, 1, 1, 0]),\n",
       "  'FLAG_OWN_CAR': tensor([0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0,\n",
       "          0, 1, 0, 0, 0, 1, 0, 0]),\n",
       "  'FLAG_OWN_REALTY': tensor([1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'CNT_CHILDREN': [tensor([0.2105, 0.0000, 0.0000, 0.0000, 0.0526, 0.1053, 0.0526, 0.0526, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1053, 0.0000, 0.0526,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.1053, 0.0000, 0.0000, 0.0000, 0.1053]),\n",
       "   tensor([5, 1, 1, 1, 2, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1,\n",
       "           1, 1, 1, 3, 1, 1, 1, 3])],\n",
       "  'AMT_INCOME_TOTAL': tensor([-0.7180, -0.7180,  0.8667,  0.2888, -0.7180, -0.4145, -0.2847, -0.7180,\n",
       "           0.0905, -0.2727, -0.4145, -0.7180, -0.1284, -0.2575,  0.2888, -0.1284,\n",
       "          -0.4145,  0.4503,  0.1848,  0.0905,  0.6201,  0.9727,  0.2888, -0.2969,\n",
       "          -0.4145,  1.2199,  0.5190, -0.4145,  1.3500,  0.8667, -0.1284, -1.4030]),\n",
       "  'AMT_CREDIT': tensor([-0.9852, -1.1905,  1.2284, -0.5860, -0.6724,  0.7476, -0.2228, -1.0411,\n",
       "          -0.8524,  0.1886, -0.9293, -0.1750, -0.3703,  1.7125, -0.7096,  0.5341,\n",
       "          -0.5342,  0.7476,  0.8555,  2.1578, -0.1933,  3.5149,  0.0139, -1.1529,\n",
       "           1.5204,  2.9836,  1.3284,  0.8428, -0.2125,  2.3526, -1.0411, -1.0970]),\n",
       "  'AMT_ANNUITY': tensor([-1.1713, -1.0134,  0.8470,  0.1175, -0.6750, -0.0463,  0.6947, -1.2488,\n",
       "          -1.0112,  0.1891, -0.6257, -0.3165, -0.2765,  0.7363, -0.1533, -0.2197,\n",
       "          -0.9095,  1.7580,  0.0322,  1.9838,  0.3110,  1.9568, -0.0243, -1.4039,\n",
       "           0.5806,  1.5427,  0.6606,  0.2772, -0.1573,  1.0700, -1.2488, -0.6911]),\n",
       "  'AMT_GOODS_PRICE': tensor([-0.9092, -1.1772,  1.5028, -0.5681, -0.6899,  0.9790, -0.2392, -0.9701,\n",
       "          -0.9092,  0.3699, -0.8483, -0.1783, -0.2392,  1.5881, -0.6899,  0.3821,\n",
       "          -0.7265,  0.9790,  0.6745,  2.1972, -0.2392,  3.4154, -0.0443, -1.0919,\n",
       "           1.4054,  3.4154,  1.2227,  0.7354, -0.2148,  2.1972, -0.9701, -1.0310]),\n",
       "  'NAME_TYPE_SUITE': tensor([0, 1, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          2, 0, 0, 0, 0, 0, 0, 0]),\n",
       "  'NAME_INCOME_TYPE': tensor([1, 1, 2, 1, 4, 1, 2, 1, 1, 1, 2, 3, 4, 1, 1, 4, 3, 2, 3, 4, 4, 3, 3, 2,\n",
       "          1, 1, 1, 1, 3, 1, 1, 1]),\n",
       "  'NAME_EDUCATION_TYPE': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "          0, 1, 0, 0, 0, 1, 2, 0]),\n",
       "  'NAME_FAMILY_STATUS': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 1, 1, 0, 3, 2, 0, 4, 0, 0, 4, 1, 0, 1, 2,\n",
       "          2, 0, 1, 0, 1, 0, 2, 0])},\n",
       " {'TARGET': tensor([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.])})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the values are now all conveniently converted to tensors. The actual processing to convert examples to batches of tensors is specified within each field.\n",
    "\n",
    "The batch is a tuple consisting of two dictionaries. The first is the dictionary of inputs, and the second is the dictionary of outpus/targets. The targets are automatically discovered by looking for fields with `is_target` set to True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's prepare the actual model to train. Our model will be simple: it embeds all categories into continuous space and concatenates all the embeddings with the numerical values. Then, it will put the resulting feature through two linear layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most cumbersome part of this process is embedding all the features and concatenating them. To make this process easier, torchtable provides the option for constructing a model that does all this processing for you just by passing a dataset. The functionality is provided through the `BatchHandlerModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtable.model import BatchHandlerModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchHandlerModel(\n",
       "  (embs): ModuleList(\n",
       "    (0): Embedding(2, 1)\n",
       "    (1): Embedding(3, 3)\n",
       "    (2): Embedding(2, 1)\n",
       "    (3): Embedding(2, 1)\n",
       "    (4): Embedding(17, 50)\n",
       "    (5): Embedding(8, 28)\n",
       "    (6): Embedding(9, 36)\n",
       "    (7): Embedding(5, 10)\n",
       "    (8): Embedding(6, 15)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BatchHandlerModel.from_dataset(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, using this feature, we can easily construct the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleModel(nn.Module):\n",
    "    def __init__(self, ds):\n",
    "        super().__init__()\n",
    "        self.batch_handler = BatchHandlerModel.from_dataset(ds)\n",
    "        self.l1 = nn.Linear(self.batch_handler.out_dim(), 32)\n",
    "        self.l2 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.batch_handler(x)\n",
    "        x = self.l1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SampleModel(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SampleModel(\n",
       "  (batch_handler): BatchHandlerModel(\n",
       "    (embs): ModuleList(\n",
       "      (0): Embedding(2, 1)\n",
       "      (1): Embedding(3, 3)\n",
       "      (2): Embedding(2, 1)\n",
       "      (3): Embedding(2, 1)\n",
       "      (4): Embedding(17, 50)\n",
       "      (5): Embedding(8, 28)\n",
       "      (6): Embedding(9, 36)\n",
       "      (7): Embedding(5, 10)\n",
       "      (8): Embedding(6, 15)\n",
       "    )\n",
       "  )\n",
       "  (l1): Linear(in_features=150, out_features=32, bias=True)\n",
       "  (l2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if it can really handle the batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0458],\n",
       "        [-0.1506],\n",
       "        [-0.0568],\n",
       "        [ 0.0862],\n",
       "        [ 0.0961],\n",
       "        [-0.2124],\n",
       "        [-0.0518],\n",
       "        [-0.0706],\n",
       "        [-0.1359],\n",
       "        [-0.1723],\n",
       "        [-0.1166],\n",
       "        [-0.1334],\n",
       "        [-0.1867],\n",
       "        [ 0.1361],\n",
       "        [-0.2082],\n",
       "        [-0.0599],\n",
       "        [-0.1815],\n",
       "        [-0.0142],\n",
       "        [-0.0444],\n",
       "        [-0.0167],\n",
       "        [-0.1260],\n",
       "        [-0.0708],\n",
       "        [-0.1113],\n",
       "        [-0.0235],\n",
       "        [-0.0471],\n",
       "        [-0.0607],\n",
       "        [-0.1434],\n",
       "        [ 0.1893],\n",
       "        [-0.1661],\n",
       "        [-0.0162],\n",
       "        [-0.0161],\n",
       "        [-0.0705]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(next(iter(train_dl))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchtable does not provide any in-house training functions, but writing the training loop is relatively simple. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "loss_func = nn.BCEWithLogitsLoss()\n",
    "opt = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:24<00:00, 298.25it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 0.2768, Validation Loss: 0.2706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:24<00:00, 298.49it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 0.2748, Validation Loss: 0.2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:24<00:00, 294.20it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 0.2743, Validation Loss: 0.2689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:23<00:00, 303.33it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 0.2739, Validation Loss: 0.2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:24<00:00, 293.09it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Training Loss: 0.2737, Validation Loss: 0.2682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:24<00:00, 296.43it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Training Loss: 0.2734, Validation Loss: 0.2697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:24<00:00, 293.28it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Training Loss: 0.2732, Validation Loss: 0.2678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:25<00:00, 283.26it/s]\n",
      "  0%|          | 0/7208 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Training Loss: 0.2729, Validation Loss: 0.2691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:24<00:00, 289.60it/s]\n",
      "  0%|          | 1/7208 [00:00<23:41,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, Training Loss: 0.2729, Validation Loss: 0.2677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7208/7208 [00:23<00:00, 304.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Training Loss: 0.2726, Validation Loss: 0.2686\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    model.train() # turn on training mode\n",
    "    for x, y in tqdm.tqdm(train_dl): # thanks to our wrapper, we can intuitively iterate over our data!\n",
    "        opt.zero_grad()\n",
    "\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y[\"TARGET\"].unsqueeze(1))\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        running_loss += loss.item() * len(y[\"TARGET\"])\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_ds)\n",
    "    \n",
    "    # calculate the validation loss for this epoch\n",
    "    val_loss = 0.0\n",
    "    model.eval() # turn on evaluation mode\n",
    "    for x, y in val_dl:\n",
    "        preds = model(x)\n",
    "        loss = loss_func(preds, y[\"TARGET\"].unsqueeze(1))\n",
    "        val_loss += loss.item() * len(y[\"TARGET\"])\n",
    "\n",
    "    val_loss /= len(val_ds)\n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the training loss is gradually decreasing, it looks like it's working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic flow in torchtable can be summarized as follows:\n",
    "\n",
    "1. Determine what kind of preprocessing to apply to each column.\n",
    "2. Construct a dataset\n",
    "3. Construct a data loader from a dataset\n",
    "4. Construct a model using the dataset.\n",
    "5. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In future examples, we will cover how to create custom Fields to apply arbitrary preprocessing, how to create loaders that perform some special processing, and many more topics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
